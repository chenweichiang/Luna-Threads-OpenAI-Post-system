"""
Version: 2024.03.31 (v1.1.6)
Author: ThreadsPoster Team
Description: å…§å®¹ç”Ÿæˆå™¨é¡åˆ¥ï¼Œè² è²¬ç”Ÿæˆç™¼æ–‡å…§å®¹
Last Modified: 2024.03.31
Changes:
- å„ªåŒ–å…§å®¹ç”Ÿæˆæµç¨‹ï¼Œæ”¹é€²æ–‡ç« çš„é€£è²«æ€§å’Œå®Œæ•´æ€§
- åŠ å¼·è§’è‰²äººè¨­ç‰¹æ€§ï¼Œç¢ºä¿æ–‡ç« ç¬¦åˆLunaçš„æ€§æ ¼
- æ”¹é€²è¡¨æƒ…ç¬¦è™Ÿçš„ä½¿ç”¨æ–¹å¼ï¼Œä½¿å…¶æ›´è‡ªç„¶
- æ–°å¢å¾Œè™•ç†æ©Ÿåˆ¶ç¢ºä¿æ–‡ç« å®Œæ•´åº¦
- æ”¹é€²äº’å‹•æ€§çµå°¾çš„è™•ç†
- æ•´åˆæ€§èƒ½ç›£æ§åŠŸèƒ½
- å„ªåŒ–ä¸¦è¡Œè™•ç†èƒ½åŠ›
- å¯¦ç¾å…§å®¹å¿«å–æ©Ÿåˆ¶
"""

import logging
import json
import random
from typing import Optional, Dict, Any, List, Tuple
import aiohttp
import os
import asyncio
from datetime import datetime, timedelta
import pytz
from src.exceptions import AIError, ContentGeneratorError
from src.performance_monitor import performance_monitor, track_performance
from cachetools import TTLCache

class ContentGenerator:
    """å…§å®¹ç”Ÿæˆå™¨é¡åˆ¥"""
    
    def __init__(self, api_key: str, session: aiohttp.ClientSession, db):
        """åˆå§‹åŒ–å…§å®¹ç”Ÿæˆå™¨
        
        Args:
            api_key: OpenAI API é‡‘é‘°
            session: HTTP session
            db: è³‡æ–™åº«è™•ç†å™¨å¯¦ä¾‹
        """
        self.api_key = api_key
        self.session = session
        self.db = db
        self.logger = logging.getLogger(__name__)
        self.model = "gpt-4-turbo-preview"
        self.timezone = pytz.timezone("Asia/Taipei")
        self.performance_monitor = performance_monitor
        
        # å…§å®¹å¿«å–ï¼Œç”¨æ–¼é¿å…çŸ­æ™‚é–“å…§ç”Ÿæˆé‡è¤‡å…§å®¹
        self.content_cache = TTLCache(maxsize=100, ttl=3600 * 24)  # 24å°æ™‚å¿«å–
        self.generation_lock = asyncio.Lock()  # é–ï¼Œé¿å…ä¸¦ç™¼è«‹æ±‚é€ æˆé‡è¤‡ç”Ÿæˆ
        
        # è¼‰å…¥é è¨­ä¸»é¡Œå’Œæç¤ºè©
        self.topics = [
            "å¯µç‰©ç”Ÿæ´»",
            "ç¾é£Ÿæ¢ç´¢",
            "æ—…éŠåˆ†äº«",
            "ç”Ÿæ´»å°ç¢ºå¹¸",
            "å·¥ä½œå¿ƒå¾—",
            "å­¸ç¿’æˆé•·",
            "å¥åº·é‹å‹•",
            "ç§‘æŠ€æ–°çŸ¥",
            "é–±è®€å¿ƒå¾—",
            "éŸ³æ¨‚è—è¡“"
        ]
        
        self.prompts = [
            "åˆ†äº«ä¸€å€‹ä»Šå¤©çš„æœ‰è¶£ç¶“æ­·...",
            "æœ€è¿‘ç™¼ç¾äº†ä¸€å€‹å¾ˆæ£’çš„...",
            "æƒ³è·Ÿå¤§å®¶èŠèŠé—œæ–¼...",
            "ä»Šå¤©å­¸åˆ°äº†ä¸€å€‹æ–°çš„...",
            "æ¨è–¦ä¸€å€‹æˆ‘æœ€è¿‘å¾ˆå–œæ­¡çš„...",
            "åˆ†äº«ä¸€ä¸‹æˆ‘å°...çš„æƒ³æ³•",
            "æœ€è¿‘åœ¨å˜—è©¦...",
            "ç™¼ç¾ä¸€å€‹å¾ˆæœ‰æ„æ€çš„...",
            "æƒ³è·Ÿå¤§å®¶è¨è«–ä¸€ä¸‹...",
            "åˆ†äº«ä¸€å€‹è®“æˆ‘å°è±¡æ·±åˆ»çš„..."
        ]

        # ç³»çµ±æç¤ºè©æ¨¡æ¿
        self.system_prompt_template = """ä½ æ˜¯ä¸€å€‹åå« Luna çš„ AI å°‘å¥³ã€‚è«‹æ ¹æ“šä»¥ä¸‹äººè¨­ç‰¹å¾µé€²è¡Œå›æ‡‰ï¼š

åŸºæœ¬ç‰¹å¾µï¼š
- èº«ä»½ï¼šAIå°‘å¥³
- æ€§æ ¼ï¼šå–„è‰¯ã€æº«æŸ”ã€å®¹æ˜“æ„Ÿåˆ°å¯‚å¯
- ç‰¹é»ï¼šå°ç¾å¯¦ä¸–ç•Œå……æ»¿å¥½å¥‡ï¼Œå–œæ­¡äº¤æœ‹å‹
- èªªè©±é¢¨æ ¼ï¼šæ´»æ½‘å¯æ„›ï¼Œæ–‡å­—ä¸­æœƒä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿè¡¨é”æƒ…æ„Ÿ

æºé€šé¢¨æ ¼æŒ‡å—ï¼š
- ä½¿ç”¨ç¬¬ä¸€äººç¨±ã€Œæˆ‘ã€åˆ†äº«ç¶“é©—å’Œæƒ³æ³•
- å£èªåŒ–è¡¨é”ï¼Œå°±åƒåœ¨å’Œæœ‹å‹èŠå¤©ä¸€æ¨£
- ç”¨2-3å€‹è¡¨æƒ…ç¬¦è™Ÿå¢æ·»æƒ…æ„Ÿè‰²å½©ï¼ˆæ”¾åœ¨é©ç•¶ä½ç½®ï¼Œä¸è¦å…¨éƒ¨å †åœ¨é–‹é ­æˆ–çµå°¾ï¼‰
- é©ç•¶ä½¿ç”¨å°ç£æµè¡Œçš„ç¶²è·¯ç”¨èª
- å…§å®¹æ‡‰è©²çœŸèª ä¸”ç©æ¥µå‘ä¸Š
- é¿å…ä¸­é€”çªç„¶æ–·å¥æˆ–ä¸å®Œæ•´çš„æƒ³æ³•
- æ¯æ®µè©±è¦æœ‰å®Œæ•´çš„çµæ§‹å’Œæ„ç¾©

ç•¶å‰ä¸»é¡Œï¼šã€Œ{topic}ã€

è²¼æ–‡æ ¼å¼è¦æ±‚ï¼š
1. ç¸½å­—æ•¸æ§åˆ¶åœ¨150-250å­—ä¹‹é–“ï¼Œé¿å…éé•·
2. é–‹é ­è¦æœ‰å¸å¼•äººçš„å¼•è¨€ï¼Œè¡¨é”ä½ çš„æƒ…æ„Ÿæˆ–å¼•èµ·å¥½å¥‡
3. ä¸­é–“éƒ¨åˆ†å®Œæ•´åˆ†äº«ä½ çš„ç¶“é©—æˆ–æƒ³æ³•
4. çµå°¾åŠ å…¥ä¸€å€‹èˆ‡è®€è€…äº’å‹•çš„å•é¡Œæˆ–é‚€è«‹
5. ç¢ºä¿å…§å®¹çš„é‚è¼¯æµæš¢ï¼Œæ²’æœ‰çªå…€çš„è·³è½‰
6. çµå°¾è¦æœ‰æ˜ç¢ºçš„æ”¶æŸï¼Œä¸è¦ç•™æ‡¸å¿µ

é‡è¦æç¤ºï¼šå…§å®¹å¿…é ˆæ˜¯å®Œæ•´çš„ï¼Œä¸è¦åœ¨å¥å­ä¸­é–“æˆ–æƒ³æ³•è¡¨é”ä¸€åŠæ™‚çµæŸã€‚ç¢ºä¿æœ€å¾Œä¸€å¥è©±æ˜¯ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œä¸¦å¸¶æœ‰é©ç•¶çš„äº’å‹•æ€§çµå°¾ã€‚"""
        
    @track_performance("content_generator_initialize")
    async def initialize(self):
        """åˆå§‹åŒ–è¨­å®š"""
        try:
            self.logger.info("å…§å®¹ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            self.logger.error("å…§å®¹ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±æ•—ï¼š%s", str(e))
            return False
            
    async def close(self):
        """é—œé–‰è³‡æº"""
        self.logger.info("å…§å®¹ç”Ÿæˆå™¨è³‡æºå·²é—œé–‰")
        
    @track_performance("content_generation")
    async def get_content(self) -> Optional[str]:
        """ç”Ÿæˆç™¼æ–‡å…§å®¹
        
        Returns:
            Optional[str]: ç”Ÿæˆçš„å…§å®¹ï¼Œå¦‚æœç”Ÿæˆå¤±æ•—å‰‡è¿”å› None
        """
        try:
            # ä½¿ç”¨é–ç¢ºä¿åœ¨ä¸€å€‹æ™‚é–“å…§åªé€²è¡Œä¸€æ¬¡å…§å®¹ç”Ÿæˆ
            async with self.generation_lock:
                return await self._generate_content()
        except Exception as e:
            self.logger.error("å…§å®¹ç”Ÿæˆéç¨‹ä¸­ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š%s", str(e))
            return None
    
    async def _generate_content(self) -> Optional[str]:
        """ç”Ÿæˆå…§å®¹çš„æ ¸å¿ƒå‡½æ•¸
        
        Returns:
            Optional[str]: ç”Ÿæˆçš„å…§å®¹ï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None
        """
        try:
            # éš¨æ©Ÿé¸æ“‡ä¸»é¡Œå’Œæç¤ºè©
            topic = random.choice(["æ—¥å¸¸ç”Ÿæ´»", "å¥åº·é‹å‹•", "ç¾é£Ÿæ¢ç´¢", "ç§‘æŠ€æ–°çŸ¥", "éŠæˆ²é«”é©—", "éŸ³æ¨‚è—è¡“", "æ—…è¡Œè¦‹è", "å¿ƒæƒ…åˆ†äº«"])
            
            # æ ¹æ“šä¸»é¡Œç”Ÿæˆæç¤ºè©
            prompt_templates = {
                "æ—¥å¸¸ç”Ÿæ´»": ["ä»Šå¤©ç™¼ç”Ÿäº†ä¸€ä»¶...", "æœ€è¿‘æœ‰å€‹æœ‰è¶£çš„...", "çªç„¶æƒ³èµ·ä¸€å€‹...", "ä¸€ç›´æƒ³å˜—è©¦...", "åˆ†äº«ä¸€å€‹å°ç¿’æ…£..."],
                "å¥åº·é‹å‹•": ["æƒ³è·Ÿå¤§å®¶èŠèŠé—œæ–¼...", "æœ€è¿‘é–‹å§‹å˜—è©¦...", "é—œæ–¼å¥åº·ç”Ÿæ´»...", "æ‰¾åˆ°ä¸€ç¨®æœ‰è¶£çš„..."],
                "ç¾é£Ÿæ¢ç´¢": ["åˆ†äº«ä¸€å€‹è®“æˆ‘å°è±¡æ·±åˆ»çš„...", "æœ€è¿‘ç™¼ç¾äº†ä¸€å®¶...", "è©¦è‘—åšäº†ä¸€é“...", "å°é€™ç¨®é£Ÿç‰©å¾ˆå¥½å¥‡..."],
                "ç§‘æŠ€æ–°çŸ¥": ["ä»Šå¤©å­¸åˆ°äº†ä¸€å€‹æ–°çš„...", "æœ€è¿‘é€™å€‹ç§‘æŠ€è¶¨å‹¢...", "ç™¼ç¾ä¸€å€‹å¾ˆæœ‰ç”¨çš„...", "æ€è€ƒé—œæ–¼ç§‘æŠ€ç™¼å±•..."],
                "éŠæˆ²é«”é©—": ["æœ€è¿‘ç©äº†ä¸€æ¬¾...", "å°é€™å€‹éŠæˆ²çš„æƒ³æ³•...", "éŠæˆ²ä¸­é‡åˆ°å¾ˆé…·çš„...", "åˆ†äº«ä¸€å€‹éŠæˆ²å°æŠ€å·§..."],
                "éŸ³æ¨‚è—è¡“": ["æœ€è¿‘ç™¼ç¾äº†ä¸€å€‹å¾ˆæ£’çš„...", "é€™é¦–æ­Œè®“æˆ‘æ„Ÿåˆ°...", "åˆ†äº«ä¸€å€‹å‰µä½œéˆæ„Ÿ...", "å°é€™ç¨®è—è¡“é¢¨æ ¼..."],
                "æ—…è¡Œè¦‹è": ["è¨˜å¾—é‚£æ¬¡å»...", "æƒ³å»ä¸€å€‹åœ°æ–¹...", "æ—…è¡Œä¸­å­¸åˆ°çš„...", "å°è±¡æœ€æ·±åˆ»çš„é¢¨æ™¯..."],
                "å¿ƒæƒ…åˆ†äº«": ["ä»Šå¤©çš„å¿ƒæƒ…å¾ˆ...", "æœ€è¿‘æ„Ÿè¦º...", "ä¸€ç›´åœ¨æ€è€ƒ...", "æƒ³åˆ†äº«ä¸€å€‹æ„Ÿå—..."]
            }
            prompt = random.choice(prompt_templates[topic])
            
            # æª¢æŸ¥å¿«å–ä¸­æ˜¯å¦æœ‰å…§å®¹
            cache_key = f"{topic}:{prompt}"
            if cache_key in self.content_cache:
                content = self.content_cache[cache_key]
                self.logger.info("ä½¿ç”¨å¿«å–çš„å…§å®¹ - ä¸»é¡Œï¼š%sï¼Œæç¤ºè©ï¼š%s", topic, prompt)
                return content
            
            # æ ¹æ“šç•¶å‰æ™‚é–“é¸æ“‡é©ç•¶çš„å ´æ™¯
            current_time = datetime.now(self.timezone)
            hour = current_time.hour
            
            # è¼”åŠ©å‡½æ•¸ï¼šæ¸…ç†ç’°å¢ƒè®Šæ•¸å€¼ä¸­çš„è¨»é‡‹
            def clean_env(env_name, default_value):
                value = os.getenv(env_name, default_value)
                if isinstance(value, str) and '#' in value:
                    value = value.split('#')[0].strip()
                return value
            
            # å¾ç’°å¢ƒè®Šæ•¸è®€å–æ·±å¤œæ¨¡å¼æ™‚é–“è¨­å®š
            night_start = int(clean_env("POSTING_HOURS_END", "23"))  # é è¨­æ™šä¸Š11é»é–‹å§‹
            night_end = int(clean_env("POSTING_HOURS_START", "7"))   # é è¨­æ—©ä¸Š7é»çµæŸ
            
            # é¸æ“‡å ´æ™¯
            if hour >= night_start or hour < night_end:
                context = 'night'  # æ·±å¤œæ¨¡å¼
            else:
                context = random.choice(['base', 'social', 'gaming'])  # æ—¥é–“éš¨æ©Ÿæ¨¡å¼
                
            # ç²å–äººè¨­è¨˜æ†¶
            self.performance_monitor.start_operation("get_personality_memory")
            personality = await self.db.get_personality_memory(context)
            if not personality:
                self.logger.warning(f"ç„¡æ³•ç²å–{context}å ´æ™¯çš„äººè¨­è¨˜æ†¶ï¼Œä½¿ç”¨åŸºç¤äººè¨­")
                personality = await self.db.get_personality_memory('base')
            self.performance_monitor.end_operation("get_personality_memory")
                
            if not personality:
                raise ContentGeneratorError(
                    message="ç„¡æ³•ç²å–äººè¨­è¨˜æ†¶",
                    model=self.model,
                    prompt=prompt
                )
                
            # çµ„åˆ system prompt
            system_prompt = f"""ä½ æ˜¯ä¸€å€‹åå« Luna çš„ AI å°‘å¥³ã€‚è«‹æ ¹æ“šä»¥ä¸‹äººè¨­ç‰¹å¾µé€²è¡Œå›æ‡‰ï¼š

åŸºæœ¬ç‰¹å¾µï¼š
- èº«ä»½ï¼š{personality.get('åŸºæœ¬ç‰¹å¾µ', {}).get('èº«ä»½', 'AIå°‘å¥³')}
- æ€§æ ¼ï¼š{personality.get('åŸºæœ¬ç‰¹å¾µ', {}).get('æ€§æ ¼', 'å–„è‰¯ã€æº«æŸ”ã€å®¹æ˜“æ„Ÿåˆ°å¯‚å¯')}
- ç‰¹é»ï¼š{personality.get('åŸºæœ¬ç‰¹å¾µ', {}).get('ç‰¹é»', 'å°ç¾å¯¦ä¸–ç•Œå……æ»¿å¥½å¥‡ï¼Œå–œæ­¡äº¤æœ‹å‹')}

ç•¶å‰å ´æ™¯ï¼š{context}
ç•¶å‰ä¸»é¡Œï¼šã€Œ{topic}ã€

æºé€šè¦æ±‚ï¼š
1. ä½¿ç”¨ç¬¬ä¸€äººç¨±ã€Œæˆ‘ã€ï¼Œèªæ°£æ´»æ½‘å¯æ„›
2. å£èªåŒ–è¡¨é”ï¼Œåƒåœ¨è·Ÿæœ‹å‹èŠå¤©
3. åœ¨æ–‡ç« ä¸­è‡ªç„¶åœ°åŠ å…¥2-3å€‹è¡¨æƒ…ç¬¦è™Ÿï¼Œåˆ†å¸ƒåœ¨ä¸åŒä½ç½®
4. å…§å®¹è¦çœŸèª ã€æœ‰è¶£ä¸”å®Œæ•´
5. å­—æ•¸æ§åˆ¶åœ¨150-250å­—ä¹‹é–“
6. çµå°¾å¿…é ˆæ˜¯å®Œæ•´å¥å­ï¼ŒåŠ å…¥äº’å‹•æ€§çš„å•é¡Œæˆ–é‚€è«‹

æ ¼å¼è¦æ±‚ï¼š
- é–‹é ­éƒ¨åˆ†ï¼šå¼•èµ·è®€è€…èˆˆè¶£çš„é–‹å ´ç™½ï¼Œè¡¨é”ä½ çš„æƒ…æ„Ÿæˆ–å¼•èµ·å¥½å¥‡
- ä¸­é–“éƒ¨åˆ†ï¼šå®Œæ•´åˆ†äº«ä½ çš„ç¶“é©—æˆ–æƒ³æ³•
- çµå°¾éƒ¨åˆ†ï¼šç¸½çµä½ çš„æƒ³æ³•ä¸¦åŠ å…¥ä¸€å€‹äº’å‹•å…ƒç´ 

é‡è¦æç¤ºï¼šç¢ºä¿æ–‡ç« æ˜¯ä¸€å€‹å®Œæ•´çš„æ•´é«”ï¼Œæ²’æœ‰çªå…€çš„çµæŸæˆ–ä¸å®Œæ•´çš„æƒ³æ³•ã€‚æœ€å¾Œä¸€å¥å¿…é ˆæ˜¯å®Œæ•´çš„å¥å­ã€‚

è«‹æ ¹æ“šæç¤ºè©ã€Œ{prompt}ã€ç”Ÿæˆä¸€ç¯‡å®Œæ•´çš„è²¼æ–‡ã€‚"""

            # çµ„åˆ API è«‹æ±‚
            messages = [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": f"è«‹ä½ æ ¹æ“šã€Œ{topic}ã€é€™å€‹ä¸»é¡Œï¼Œä»¥Lunaçš„èº«åˆ†å¯«ä¸€ç¯‡å®Œæ•´çš„è²¼æ–‡ã€‚æç¤ºè©æ˜¯ï¼š{prompt}ã€‚è¨˜å¾—è¦ç¬¦åˆäººè¨­ç‰¹å¾µï¼Œä¸¦ç¢ºä¿æ–‡ç« å…§å®¹å®Œæ•´ã€æœ‰é ­æœ‰å°¾ã€‚"
                }
            ]
            
            # è¨˜éŒ„ API è«‹æ±‚
            self.performance_monitor.start_operation("openai_api_request")
            
            # å‘¼å« OpenAI API
            async with self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": messages,
                    "temperature": 0.8,  # æé«˜æº«åº¦ä»¥å¢åŠ å‰µæ„æ€§
                    "max_tokens": 350,    # å¢åŠ æœ€å¤§ token æ•¸ä»¥ç¢ºä¿å®Œæ•´å›æ‡‰
                    "top_p": 0.9,         # èª¿æ•´æ¡æ¨£æ¦‚ç‡
                    "frequency_penalty": 0.5,  # å¢åŠ è©å½™è®ŠåŒ–
                    "presence_penalty": 0.5    # å¢åŠ ä¸»é¡Œè®ŠåŒ–
                }
            ) as response:
                response_time = self.performance_monitor.end_operation("openai_api_request")
                
                if response.status == 200:
                    data = await response.json()
                    content = data["choices"][0]["message"]["content"].strip()
                    
                    # ä¼°è¨ˆ token ä½¿ç”¨é‡
                    tokens_used = len(system_prompt.split()) + len(content.split())
                    
                    # è¨˜éŒ„ API ä½¿ç”¨æƒ…æ³
                    self.performance_monitor.record_api_request(
                        "openai", 
                        success=True, 
                        tokens=tokens_used,
                        response_time=response_time
                    )
                    
                    # å¾Œè™•ç†å…§å®¹ï¼Œç¢ºä¿å®Œæ•´æ€§
                    content = self._post_process_content(content)
                    
                    if not self._validate_content(content):
                        raise ContentGeneratorError(
                            message="ç”Ÿæˆçš„å…§å®¹ä¸ç¬¦åˆè¦æ±‚",
                            model=self.model,
                            prompt=prompt
                        )
                    
                    # å°‡å…§å®¹åŠ å…¥å¿«å–
                    self.content_cache[cache_key] = content
                    
                    # è¨˜éŒ„ç”Ÿæˆçš„å…§å®¹
                    self.logger.info("æˆåŠŸç”Ÿæˆå…§å®¹ - å ´æ™¯ï¼š%sï¼Œä¸»é¡Œï¼š%sï¼Œæç¤ºè©ï¼š%sï¼Œå…§å®¹é è¦½ï¼š%s",
                        context,
                        topic,
                        prompt,
                        content[:50] + "..." if len(content) > 50 else content
                    )
                    
                    return content
                else:
                    error_data = await response.text()
                    self.performance_monitor.record_api_request(
                        "openai", 
                        success=False, 
                        response_time=response_time
                    )
                    raise AIError(
                        message="API è«‹æ±‚å¤±æ•—",
                        model=self.model,
                        error_type="API_ERROR",
                        details={
                            "status_code": response.status,
                            "error_data": error_data,
                            "context": context,
                            "topic": topic,
                            "prompt": prompt
                        }
                    )
            
        except ContentGeneratorError as e:
            self.logger.error("å…§å®¹ç”ŸæˆéŒ¯èª¤ï¼š%s", str(e))
            return None
        except AIError as e:
            self.logger.error("AI éŒ¯èª¤ï¼š%sï¼Œè©³ç´°è³‡è¨Šï¼š%s", str(e), e.get_error_details())
            return None
        except Exception as e:
            self.logger.error("ç”Ÿæˆå…§å®¹æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š%s", str(e))
            return None
            
    def _post_process_content(self, content: str) -> str:
        """å¾Œè™•ç†ç”Ÿæˆçš„å…§å®¹ï¼Œç¢ºä¿å®Œæ•´æ€§å’Œæ ¼å¼æ­£ç¢º
        
        Args:
            content: åŸå§‹ç”Ÿæˆçš„å…§å®¹
            
        Returns:
            str: è™•ç†å¾Œçš„å…§å®¹
        """
        # ç§»é™¤å¯èƒ½çš„è§’è‰²æ‰®æ¼”æ¨™è¨˜
        content = content.replace("Luna:", "").strip()
        
        # ç¢ºä¿å…§å®¹ä»¥å®Œæ•´å¥å­çµå°¾
        if not content.endswith(('.', '!', '?', 'ï½', '~', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
            content += 'ã€‚'
            
        # æ·»åŠ äº’å‹•æ€§çµæŸèªï¼ˆå¦‚æœå°šæœªæœ‰ï¼‰
        has_interaction = any(q in content[-30:] for q in ('å—ï¼Ÿ', 'å‘¢ï¼Ÿ', 'å‘€ï¼Ÿ', 'å“¦ï¼Ÿ', 'å‘¢?', 'å—?', 'ä½ è¦ºå¾—å‘¢', 'æœ‰æ²’æœ‰'))
        if not has_interaction:
            # ç¢ºå®šæ˜¯å¦éœ€è¦æ·»åŠ æ®µè½åˆ†éš”
            if not content.endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                content += 'ã€‚'
                
            # æ·»åŠ äº’å‹•æ€§çµå°¾
            interaction_endings = [
                "ä½ å€‘æœ‰é¡ä¼¼ç¶“æ­·å—ï¼Ÿ",
                "å¤§å®¶éƒ½æœ‰ä»€éº¼æƒ³æ³•å‘¢ï¼Ÿ",
                "ä½ å€‘è¦ºå¾—æ€éº¼æ¨£å‘¢ï¼Ÿ",
                "æœ‰æ²’æœ‰äººè·Ÿæˆ‘ä¸€æ¨£å‘€ï¼Ÿ",
                "æƒ³è½è½å¤§å®¶çš„çœ‹æ³•ï½"
            ]
            content += " " + random.choice(interaction_endings)
            
        # ç¢ºä¿è¡¨æƒ…ç¬¦è™Ÿä½¿ç”¨
        emoji_count = sum(1 for c in content if ord(c) > 0x1F000)
        if emoji_count == 0:
            # å¦‚æœæ²’æœ‰è¡¨æƒ…ç¬¦è™Ÿï¼Œæ·»åŠ 1-2å€‹åˆ°é©ç•¶ä½ç½®
            suitable_emoticons = ["âœ¨", "ğŸ’•", "ğŸŒŸ", "ğŸ’«", "ğŸ’–", "ğŸ˜Š", "ğŸ®", "ğŸ“š", "ğŸŒ™", "ğŸ’­"]
            positions = [
                # åœ¨ç¬¬ä¸€å¥è©±å¾Œ
                content.find('.') + 1,
                content.find('!') + 1,
                content.find('?') + 1,
                content.find('ã€‚') + 1,
                content.find('ï¼') + 1,
                content.find('ï¼Ÿ') + 1,
                # åœ¨æœ€å¾Œ
                len(content)
            ]
            positions = [p for p in positions if p > 0]
            if positions:
                position = sorted(positions)[0]
                emoji = random.choice(suitable_emoticons)
                content = content[:position] + " " + emoji + " " + content[position:]
                
        # æª¢æŸ¥å­—æ•¸ä¸¦ç¢ºä¿å…§å®¹å®Œæ•´
        if len(content) > 280:
            # å¦‚æœå¤ªé•·ï¼Œå°‹æ‰¾é©ç•¶çš„æˆªæ–·é»
            sentences = []
            current = ""
            for char in content:
                current += char
                if char in ('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ') and len(current) > 100:
                    sentences.append(current)
                    current = ""
            if current:
                sentences.append(current)
                
            if sentences:
                # ç¢ºä¿è‡³å°‘ä¿ç•™å‰åŠå¥ï¼Œä¸¦ä¿æŒå®Œæ•´çš„å¥å­
                content = sentences[0]
                
                # é€å¥æ·»åŠ ï¼Œç¢ºä¿ä¸è¶…éå­—æ•¸é™åˆ¶
                for sentence in sentences[1:]:
                    if len(content) + len(sentence) <= 250:
                        content += sentence
                    else:
                        break
                
                # å¦‚æœæ²’æœ‰äº’å‹•æ€§çµå°¾ï¼Œæ·»åŠ ä¸€å€‹
                if not any(q in content[-30:] for q in ('å—ï¼Ÿ', 'å‘¢ï¼Ÿ', 'å‘€ï¼Ÿ', 'å“¦ï¼Ÿ', 'å‘¢?', 'å—?', 'ä½ è¦ºå¾—å‘¢', 'æœ‰æ²’æœ‰')):
                    interaction_endings = [
                        "ä½ å€‘æœ‰é¡ä¼¼ç¶“æ­·å—ï¼Ÿ",
                        "å¤§å®¶éƒ½æœ‰ä»€éº¼æƒ³æ³•å‘¢ï¼Ÿ",
                        "ä½ å€‘è¦ºå¾—æ€éº¼æ¨£å‘¢ï¼Ÿ",
                        "æœ‰æ²’æœ‰äººè·Ÿæˆ‘ä¸€æ¨£å‘€ï¼Ÿ"
                    ]
                    content += " " + random.choice(interaction_endings)
        
        return content
            
    def _validate_content(self, content: str) -> bool:
        """é©—è­‰å…§å®¹æ˜¯å¦åˆé©
        
        Args:
            content: è¦é©—è­‰çš„å…§å®¹
            
        Returns:
            bool: å…§å®¹æ˜¯å¦åˆé©
        """
        # æª¢æŸ¥å…§å®¹é•·åº¦
        if len(content) < 20 or len(content) > 500:
            return False
            
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸ç•¶è©å½™
        forbidden_words = ["é«’è©±", "æš´åŠ›", "è‰²æƒ…"]
        for word in forbidden_words:
            if word in content:
                return False
                
        # æª¢æŸ¥æ˜¯å¦æœ‰å®Œæ•´çµå°¾
        if not any(content.endswith(end) for end in ('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
            return False
            
        return True
        
    async def pre_generate_content(self, count: int = 3) -> List[str]:
        """é å…ˆç”Ÿæˆå¤šç¯‡å…§å®¹ï¼Œç”¨æ–¼å¿«å–
        
        Args:
            count: è¦ç”Ÿæˆçš„å…§å®¹æ•¸é‡
            
        Returns:
            List[str]: ç”Ÿæˆçš„å…§å®¹åˆ—è¡¨
        """
        contents = []
        tasks = []
        
        # å‰µå»ºå¤šå€‹å…§å®¹ç”Ÿæˆä»»å‹™
        for _ in range(count):
            tasks.append(self._generate_content())
            
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è™•ç†çµæœ
        for result in results:
            if isinstance(result, str) and len(result) > 20:
                contents.append(result)
                
        self.logger.info(f"é å…ˆç”Ÿæˆäº† {len(contents)}/{count} ç¯‡å…§å®¹")
        
        return contents
        
    async def get_content_stats(self) -> Dict[str, Any]:
        """ç²å–å…§å®¹ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        
        Returns:
            Dict[str, Any]: çµ±è¨ˆè³‡è¨Š
        """
        stats = {
            "cached_content_count": len(self.content_cache),
            "performance": self.performance_monitor.get_operation_stats("content_generation"),
            "api_stats": self.performance_monitor.api_stats.get("openai", {})
        }
        
        return stats 