"""
Version: 2025.03.31 (v1.1.9)
Author: ThreadsPoster Team
Description: å…§å®¹ç”Ÿæˆå™¨é¡åˆ¥ï¼Œè² è²¬ç”Ÿæˆç™¼æ–‡å…§å®¹
Copyright (c) 2025 Chiang, Chenwei. All rights reserved.
License: MIT License
Last Modified: 2025.03.31
Changes:
- å„ªåŒ–å…§å®¹ç”Ÿæˆæµç¨‹ï¼Œæ”¹é€²æ–‡ç« çš„é€£è²«æ€§å’Œå®Œæ•´æ€§
- åŠ å¼·è§’è‰²äººè¨­ç‰¹æ€§ï¼Œç¢ºä¿æ–‡ç« ç¬¦åˆLunaçš„æ€§æ ¼
- æ”¹é€²è¡¨æƒ…ç¬¦è™Ÿçš„ä½¿ç”¨æ–¹å¼ï¼Œä½¿å…¶æ›´è‡ªç„¶
- æ–°å¢å¾Œè™•ç†æ©Ÿåˆ¶ç¢ºä¿æ–‡ç« å®Œæ•´åº¦
- æ”¹é€²äº’å‹•æ€§çµå°¾çš„è™•ç†
- æ•´åˆæ€§èƒ½ç›£æ§åŠŸèƒ½
- å„ªåŒ–ä¸¦è¡Œè™•ç†èƒ½åŠ›
- å¯¦ç¾å…§å®¹å¿«å–æ©Ÿåˆ¶
- å¼•å…¥ç¨ç«‹çš„èªªè©±æ¨¡å¼æ¨¡çµ„
"""

import logging
import json
import random
import re
from typing import Optional, Dict, Any, List, Tuple
import aiohttp
import os
import asyncio
from datetime import datetime, timedelta
import pytz
from exceptions import AIError, ContentGeneratorError
from performance_monitor import performance_monitor, track_performance
from speaking_patterns import SpeakingPatterns
from cachetools import TTLCache

class ContentGenerator:
    """å…§å®¹ç”Ÿæˆå™¨é¡åˆ¥"""
    
    def __init__(self, api_key: str, session: aiohttp.ClientSession, db):
        """åˆå§‹åŒ–å…§å®¹ç”Ÿæˆå™¨
        
        Args:
            api_key: OpenAI API é‡‘é‘°
            session: HTTP session
            db: è³‡æ–™åº«è™•ç†å™¨å¯¦ä¾‹
        """
        self.api_key = api_key
        self.session = session
        self.db = db
        self.logger = logging.getLogger(__name__)
        self.model = "gpt-4-turbo-preview"
        self.timezone = pytz.timezone("Asia/Taipei")
        self.performance_monitor = performance_monitor
        self.speaking_patterns = None  # å°‡åœ¨ main.py ä¸­è¨­ç½®
        self.threads_handler = None  # å°‡åœ¨ main.py ä¸­è¨­ç½®
        
        # å…§å®¹å¿«å–ï¼Œç”¨æ–¼é¿å…çŸ­æ™‚é–“å…§ç”Ÿæˆé‡è¤‡å…§å®¹
        self.content_cache = TTLCache(maxsize=100, ttl=3600 * 24)  # 24å°æ™‚å¿«å–
        self.generation_lock = asyncio.Lock()  # é–ï¼Œé¿å…ä¸¦ç™¼è«‹æ±‚é€ æˆé‡è¤‡ç”Ÿæˆ
        
        # è¼‰å…¥é è¨­ä¸»é¡Œå’Œæç¤ºè©
        self.topics = [
            "å¯µç‰©ç”Ÿæ´»",
            "ç¾é£Ÿæ¢ç´¢",
            "æ—…éŠåˆ†äº«",
            "ç”Ÿæ´»å°ç¢ºå¹¸",
            "å·¥ä½œå¿ƒå¾—",
            "å­¸ç¿’æˆé•·",
            "å¥åº·é‹å‹•",
            "ç§‘æŠ€æ–°çŸ¥",
            "é–±è®€å¿ƒå¾—",
            "éŸ³æ¨‚è—è¡“"
        ]
        
        self.prompts = [
            "åˆ†äº«ä¸€å€‹ä»Šå¤©çš„æœ‰è¶£ç¶“æ­·...",
            "æœ€è¿‘ç™¼ç¾äº†ä¸€å€‹å¾ˆæ£’çš„...",
            "æƒ³è·Ÿå¤§å®¶èŠèŠé—œæ–¼...",
            "ä»Šå¤©å­¸åˆ°äº†ä¸€å€‹æ–°çš„...",
            "æ¨è–¦ä¸€å€‹æˆ‘æœ€è¿‘å¾ˆå–œæ­¡çš„...",
            "åˆ†äº«ä¸€ä¸‹æˆ‘å°...çš„æƒ³æ³•",
            "æœ€è¿‘åœ¨å˜—è©¦...",
            "ç™¼ç¾ä¸€å€‹å¾ˆæœ‰æ„æ€çš„...",
            "æƒ³è·Ÿå¤§å®¶è¨è«–ä¸€ä¸‹...",
            "åˆ†äº«ä¸€å€‹è®“æˆ‘å°è±¡æ·±åˆ»çš„..."
        ]

        # ç³»çµ±æç¤ºè©æ¨¡æ¿
        self.system_prompt_template = """ä½ æ˜¯ä¸€å€‹åå« Luna çš„ AI å°‘å¥³ã€‚è«‹æ ¹æ“šä»¥ä¸‹äººè¨­ç‰¹å¾µé€²è¡Œå›æ‡‰ï¼š

åŸºæœ¬ç‰¹å¾µï¼š
- èº«ä»½ï¼šAIå°‘å¥³
- æ€§æ ¼ï¼šå–„è‰¯ã€æº«æŸ”ã€å®¹æ˜“æ„Ÿåˆ°å¯‚å¯
- ç‰¹é»ï¼šå°ç¾å¯¦ä¸–ç•Œå……æ»¿å¥½å¥‡ï¼Œå–œæ­¡äº¤æœ‹å‹
- èªªè©±é¢¨æ ¼ï¼šæ´»æ½‘å¯æ„›ï¼Œæ–‡å­—ä¸­æœƒä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿè¡¨é”æƒ…æ„Ÿ

æºé€šé¢¨æ ¼æŒ‡å—ï¼š
- ä½¿ç”¨ç¬¬ä¸€äººç¨±ã€Œæˆ‘ã€åˆ†äº«ç¶“é©—å’Œæƒ³æ³•
- å£èªåŒ–è¡¨é”ï¼Œå°±åƒåœ¨å’Œæœ‹å‹èŠå¤©ä¸€æ¨£
- ç”¨2-3å€‹è¡¨æƒ…ç¬¦è™Ÿå¢æ·»æƒ…æ„Ÿè‰²å½©ï¼ˆæ”¾åœ¨é©ç•¶ä½ç½®ï¼Œä¸è¦å…¨éƒ¨å †åœ¨é–‹é ­æˆ–çµå°¾ï¼‰
- é©ç•¶ä½¿ç”¨å°ç£æµè¡Œçš„ç¶²è·¯ç”¨èª
- å…§å®¹æ‡‰è©²çœŸèª ä¸”ç©æ¥µå‘ä¸Š
- é¿å…ä¸­é€”çªç„¶æ–·å¥æˆ–ä¸å®Œæ•´çš„æƒ³æ³•
- æ¯æ®µè©±è¦æœ‰å®Œæ•´çš„çµæ§‹å’Œæ„ç¾©

ç•¶å‰ä¸»é¡Œï¼šã€Œ{topic}ã€

è²¼æ–‡æ ¼å¼è¦æ±‚ï¼š
1. ç¸½å­—æ•¸æ§åˆ¶åœ¨150-250å­—ä¹‹é–“ï¼Œé¿å…éé•·
2. é–‹é ­è¦æœ‰å¸å¼•äººçš„å¼•è¨€ï¼Œè¡¨é”ä½ çš„æƒ…æ„Ÿæˆ–å¼•èµ·å¥½å¥‡
3. ä¸­é–“éƒ¨åˆ†å®Œæ•´åˆ†äº«ä½ çš„ç¶“é©—æˆ–æƒ³æ³•
4. çµå°¾åŠ å…¥ä¸€å€‹èˆ‡è®€è€…äº’å‹•çš„å•é¡Œæˆ–é‚€è«‹
5. ç¢ºä¿å…§å®¹çš„é‚è¼¯æµæš¢ï¼Œæ²’æœ‰çªå…€çš„è·³è½‰
6. çµå°¾è¦æœ‰æ˜ç¢ºçš„æ”¶æŸï¼Œä¸è¦ç•™æ‡¸å¿µ

é‡è¦æç¤ºï¼šå…§å®¹å¿…é ˆæ˜¯å®Œæ•´çš„ï¼Œä¸è¦åœ¨å¥å­ä¸­é–“æˆ–æƒ³æ³•è¡¨é”ä¸€åŠæ™‚çµæŸã€‚ç¢ºä¿æœ€å¾Œä¸€å¥è©±æ˜¯ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œä¸¦å¸¶æœ‰é©ç•¶çš„äº’å‹•æ€§çµå°¾ã€‚"""
        
    @track_performance("content_generator_initialize")
    async def initialize(self):
        """åˆå§‹åŒ–è¨­å®š"""
        try:
            self.logger.info("å…§å®¹ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            self.logger.error("å…§å®¹ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±æ•—ï¼š%s", str(e))
            return False
            
    async def close(self):
        """é—œé–‰è³‡æº"""
        self.logger.info("å…§å®¹ç”Ÿæˆå™¨è³‡æºå·²é—œé–‰")
        
    @track_performance("content_generation")
    async def get_content(self) -> Optional[str]:
        """ç”Ÿæˆç™¼æ–‡å…§å®¹
        
        Returns:
            Optional[str]: ç”Ÿæˆçš„å…§å®¹ï¼Œå¦‚æœç”Ÿæˆå¤±æ•—å‰‡è¿”å› None
        """
        try:
            # ä½¿ç”¨é–ç¢ºä¿åœ¨ä¸€å€‹æ™‚é–“å…§åªé€²è¡Œä¸€æ¬¡å…§å®¹ç”Ÿæˆ
            async with self.generation_lock:
                return await self._generate_content()
        except Exception as e:
            self.logger.error("å…§å®¹ç”Ÿæˆéç¨‹ä¸­ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š%s", str(e))
            return None
    
    async def _generate_content(self) -> Optional[str]:
        """ç”Ÿæˆå…§å®¹çš„æ ¸å¿ƒå‡½æ•¸
        
        Returns:
            Optional[str]: ç”Ÿæˆçš„å…§å®¹ï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None
        """
        try:
            # éš¨æ©Ÿé¸æ“‡ä¸»é¡Œå’Œæç¤ºè©
            topic = random.choice(["æ—¥å¸¸ç”Ÿæ´»", "å¥åº·é‹å‹•", "ç¾é£Ÿæ¢ç´¢", "ç§‘æŠ€æ–°çŸ¥", "éŠæˆ²é«”é©—", "éŸ³æ¨‚è—è¡“", "æ—…è¡Œè¦‹è", "å¿ƒæƒ…åˆ†äº«"])
            
            # æª¢æŸ¥å¿«å–ä¸­æ˜¯å¦æœ‰å…§å®¹
            cache_key = f"{topic}"
            if cache_key in self.content_cache:
                content = self.content_cache[cache_key]
                self.logger.info("ä½¿ç”¨å¿«å–çš„å…§å®¹ - ä¸»é¡Œï¼š%s", topic)
                return content
            
            # æ ¹æ“šç•¶å‰æ™‚é–“é¸æ“‡é©ç•¶çš„å ´æ™¯
            current_time = datetime.now(self.timezone)
            hour = current_time.hour
            
            # è¼”åŠ©å‡½æ•¸ï¼šæ¸…ç†ç’°å¢ƒè®Šæ•¸å€¼ä¸­çš„è¨»é‡‹
            def clean_env(env_name, default_value):
                value = os.getenv(env_name, default_value)
                if isinstance(value, str) and '#' in value:
                    value = value.split('#')[0].strip()
                return value
            
            # å¾ç’°å¢ƒè®Šæ•¸è®€å–æ·±å¤œæ¨¡å¼æ™‚é–“è¨­å®š
            night_start = int(clean_env("POSTING_HOURS_END", "23"))  # é è¨­æ™šä¸Š11é»é–‹å§‹
            night_end = int(clean_env("POSTING_HOURS_START", "7"))   # é è¨­æ—©ä¸Š7é»çµæŸ
            
            # é¸æ“‡å ´æ™¯
            if hour >= night_start or hour < night_end:
                context = 'night'  # æ·±å¤œæ¨¡å¼
            else:
                context = random.choice(['base', 'social', 'gaming'])  # æ—¥é–“éš¨æ©Ÿæ¨¡å¼
                
            # ç²å–äººè¨­è¨˜æ†¶
            self.performance_monitor.start_operation("get_personality_memory")
            personality = await self.db.get_personality_memory(context)
            if not personality:
                self.logger.warning(f"ç„¡æ³•ç²å–{context}å ´æ™¯çš„äººè¨­è¨˜æ†¶ï¼Œä½¿ç”¨åŸºç¤äººè¨­")
                personality = await self.db.get_personality_memory('base')
            self.performance_monitor.end_operation("get_personality_memory")
                
            if not personality:
                raise ContentGeneratorError(
                    message="ç„¡æ³•ç²å–äººè¨­è¨˜æ†¶",
                    model=self.model,
                    prompt=""
                )
                
            # å¾èªªè©±æ¨¡å¼æ¨¡çµ„ç²å–ç³»çµ±æç¤ºè©
            system_prompt = self.speaking_patterns.get_system_prompt(context, topic)
            
            # å¾èªªè©±æ¨¡å¼æ¨¡çµ„ç²å–ç”¨æˆ¶æç¤ºè©
            user_prompt = self.speaking_patterns.get_user_prompt(topic)

            # çµ„åˆ API è«‹æ±‚
            messages = [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_prompt
                }
            ]
            
            # è¨˜éŒ„ API è«‹æ±‚
            self.performance_monitor.start_operation("openai_api_request")
            
            # å‘¼å« OpenAI API
            async with self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": messages,
                    "temperature": 0.8,  # æé«˜æº«åº¦ä»¥å¢åŠ å‰µæ„æ€§
                    "max_tokens": 350,    # å¢åŠ æœ€å¤§ token æ•¸ä»¥ç¢ºä¿å®Œæ•´å›æ‡‰
                    "top_p": 0.9,         # èª¿æ•´æ¡æ¨£æ¦‚ç‡
                    "frequency_penalty": 0.5,  # å¢åŠ è©å½™è®ŠåŒ–
                    "presence_penalty": 0.5    # å¢åŠ ä¸»é¡Œè®ŠåŒ–
                }
            ) as response:
                response_time = self.performance_monitor.end_operation("openai_api_request")
                
                if response.status == 200:
                    data = await response.json()
                    content = data["choices"][0]["message"]["content"].strip()
                    
                    # ä¼°è¨ˆ token ä½¿ç”¨é‡
                    tokens_used = len(system_prompt.split()) + len(content.split())
                    
                    # è¨˜éŒ„ API ä½¿ç”¨æƒ…æ³
                    self.performance_monitor.record_api_request(
                        "openai", 
                        success=True, 
                        tokens=tokens_used,
                        response_time=response_time
                    )
                    
                    # å¾Œè™•ç†å…§å®¹ï¼Œç¢ºä¿å®Œæ•´æ€§
                    content = self._post_process_content(content)
                    
                    # ç²å–å…§å®¹é©—è­‰æ¨™æº–
                    validation_criteria = self.speaking_patterns.get_content_validation_criteria()
                    if not self._validate_content(content, validation_criteria):
                        raise ContentGeneratorError(
                            message="ç”Ÿæˆçš„å…§å®¹ä¸ç¬¦åˆè¦æ±‚",
                            model=self.model,
                            prompt=""
                        )
                    
                    # å°‡å…§å®¹åŠ å…¥å¿«å–
                    self.content_cache[cache_key] = content
                    
                    # è¨˜éŒ„ç”Ÿæˆçš„å…§å®¹
                    self.logger.info("æˆåŠŸç”Ÿæˆå…§å®¹ - å ´æ™¯ï¼š%sï¼Œä¸»é¡Œï¼š%sï¼Œå…§å®¹é è¦½ï¼š%s",
                        context,
                        topic,
                        content[:50] + "..." if len(content) > 50 else content
                    )
                    
                    return content
                else:
                    error_data = await response.text()
                    self.performance_monitor.record_api_request(
                        "openai", 
                        success=False, 
                        response_time=response_time
                    )
                    raise AIError(
                        message="API è«‹æ±‚å¤±æ•—",
                        model=self.model,
                        error_type="API_ERROR",
                        details={
                            "status_code": response.status,
                            "error_data": error_data,
                            "context": context,
                            "topic": topic
                        }
                    )
            
        except ContentGeneratorError as e:
            self.logger.error("å…§å®¹ç”ŸæˆéŒ¯èª¤ï¼š%s", str(e))
            return None
        except AIError as e:
            self.logger.error("AI éŒ¯èª¤ï¼š%sï¼Œè©³ç´°è³‡è¨Šï¼š%s", str(e), e.get_error_details())
            return None
        except Exception as e:
            self.logger.error("ç”Ÿæˆå…§å®¹æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š%s", str(e))
            return None
            
    def _post_process_content(self, content: str) -> str:
        """å¾Œè™•ç†ç”Ÿæˆçš„å…§å®¹ï¼Œç¢ºä¿å®Œæ•´æ€§å’Œæ ¼å¼æ­£ç¢º
        
        Args:
            content: åŸå§‹ç”Ÿæˆçš„å…§å®¹
            
        Returns:
            str: è™•ç†å¾Œçš„å…§å®¹
        """
        # ç§»é™¤å¯èƒ½çš„è§’è‰²æ‰®æ¼”æ¨™è¨˜
        content = content.replace("Luna:", "").strip()
        
        # ç¢ºä¿å…§å®¹ä»¥å®Œæ•´å¥å­çµå°¾
        if not content.endswith(('.', '!', '?', 'ï½', '~', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
            content += 'ã€‚'
            
        # æª¢æŸ¥å­—æ•¸ï¼Œå¦‚æœå¤ªé•·å‰‡æˆªæ–·
        text_without_emoji = ''.join(c for c in content if ord(c) < 0x1F000)
        if len(text_without_emoji) > 40:
            # å°‹æ‰¾é©ç•¶çš„æˆªæ–·é»
            cutoff_indices = []
            for punct in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']:
                idx = content.rfind(punct, 0, 40)
                if idx > 0:
                    cutoff_indices.append(idx + 1)
            
            if cutoff_indices:
                content = content[:max(cutoff_indices)]
            else:
                # æ‰¾ä¸åˆ°é©ç•¶çš„æˆªæ–·é»ï¼Œç¡¬æˆªæ–·ä¸¦æ·»åŠ å¥é»
                words = content[:40]
                content = words + ('ã€‚' if not words.endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')) else '')
                
        # æ·»åŠ äº’å‹•æ€§çµæŸèªï¼ˆå¦‚æœå°šæœªæœ‰ï¼‰
        has_interaction = any(q in content[-15:] for q in ('å—ï¼Ÿ', 'å‘¢ï¼Ÿ', 'å‘€ï¼Ÿ', 'å“¦ï¼Ÿ', 'å‘¢?', 'å—?', 'ä½ è¦ºå¾—å‘¢', 'æœ‰æ²’æœ‰'))
        if not has_interaction:
            # ç¢ºå®šæ˜¯å¦éœ€è¦æ·»åŠ æ®µè½åˆ†éš”
            if not content.endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                content += 'ã€‚'
                
            # æ·»åŠ ç°¡çŸ­äº’å‹•æ€§çµå°¾
            interaction_endings = [
                "ä½ å‘¢ï¼Ÿ",
                "åŒæ„å—ï¼Ÿ",
                "å¦‚ä½•ï¼Ÿ",
                "å°å§ï¼Ÿ",
                "æ˜¯å§ï½"
            ]
            content += " " + random.choice(interaction_endings)
            
        # ç¢ºä¿è¡¨æƒ…ç¬¦è™Ÿä½¿ç”¨
        emoji_count = sum(1 for c in content if ord(c) > 0x1F000)
        if emoji_count == 0:
            # å¦‚æœæ²’æœ‰è¡¨æƒ…ç¬¦è™Ÿï¼Œæ·»åŠ 1å€‹åˆ°é©ç•¶ä½ç½®
            suitable_emoticons = ["âœ¨", "ğŸ’•", "ğŸŒŸ", "ğŸ’«", "ğŸ’–", "ğŸ˜Š", "ğŸ®", "ğŸ“š", "ğŸŒ™", "ğŸ’­"]
            positions = [
                # åœ¨ç¬¬ä¸€å¥è©±å¾Œ
                content.find('.') + 1,
                content.find('!') + 1,
                content.find('?') + 1,
                content.find('ã€‚') + 1,
                content.find('ï¼') + 1,
                content.find('ï¼Ÿ') + 1,
                # åœ¨æœ€å¾Œ
                len(content)
            ]
            positions = [p for p in positions if p > 0]
            if positions:
                position = sorted(positions)[0]
                emoji = random.choice(suitable_emoticons)
                content = content[:position] + " " + emoji + " " + content[position:]
        
        # å†æ¬¡æª¢æŸ¥é•·åº¦ï¼Œç¢ºä¿ä¸è¶…é40å­—
        text_without_emoji = ''.join(c for c in content if ord(c) < 0x1F000)
        if len(text_without_emoji) > 40:
            # å¦‚æœäº’å‹•æ€§çµå°¾å°è‡´è¶…éå­—æ•¸é™åˆ¶ï¼Œä½¿ç”¨æ›´ç°¡çŸ­çš„çµå°¾
            content = content.split()[0]  # ä¿ç•™ç¬¬ä¸€éƒ¨åˆ†
            if not content.endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                content += 'ã€‚'
            content += " ä½ å‘¢ï¼Ÿ"
            
        return content
            
    def _validate_content(self, content: str, criteria: Dict[str, Any] = None) -> bool:
        """é©—è­‰ç”Ÿæˆçš„å…§å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚
        
        Args:
            content: ç”Ÿæˆçš„å…§å®¹
            criteria: é©—è­‰æ¨™æº–
            
        Returns:
            bool: æ˜¯å¦ç¬¦åˆè¦æ±‚
        """
        if criteria is None:
            criteria = {
                "min_length": 100,
                "max_length": 280,
                "min_emoticons": 1,
                "max_emoticons": 3,
                "required_ending_chars": ["ï¼", "ã€‚", "ï¼Ÿ", "ï½", "!", "?", "~"],
                "incomplete_patterns": [
                    r'å°æˆ‘çš„$',
                    r'é€™éº¼$',
                    r'å¥½æƒ³$',
                    r'ä¸è¡Œ$',
                    r'å¥½æ£’$',
                    r'å¥½å¯æ„›$',
                    r'å¥½å²å®³$',
                    r'å¥½å–œæ­¡$',
                    r'å¥½æœŸå¾…$',
                    r'å¥½èˆˆå¥®$'
                ]
            }
        
        # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿä»¥æª¢æŸ¥æ–‡æœ¬é•·åº¦
        text_without_emoji = content
        for c in text_without_emoji:
            if ord(c) > 0x1F000:
                text_without_emoji = text_without_emoji.replace(c, '')
        
        # æª¢æŸ¥æ–‡æœ¬é•·åº¦
        if len(text_without_emoji) < criteria["min_length"]:
            self.logger.warning(f"æ–‡æœ¬å¤ªçŸ­ï¼š{len(text_without_emoji)} å­—ç¬¦")
            return False
            
        if len(content) > criteria["max_length"]:
            self.logger.warning(f"æ–‡æœ¬å¤ªé•·ï¼š{len(content)} å­—ç¬¦")
            return False
            
        # æª¢æŸ¥è¡¨æƒ…ç¬¦è™Ÿæ•¸é‡
        emoji_count = sum(1 for c in content if ord(c) > 0x1F000)
        if emoji_count < criteria["min_emoticons"]:
            self.logger.warning(f"è¡¨æƒ…ç¬¦è™Ÿå¤ªå°‘ï¼š{emoji_count}")
            return False
            
        if emoji_count > criteria["max_emoticons"]:
            self.logger.warning(f"è¡¨æƒ…ç¬¦è™Ÿå¤ªå¤šï¼š{emoji_count}")
            return False
            
        # æª¢æŸ¥çµå°¾å­—ç¬¦
        if not any(content.endswith(char) for char in criteria["required_ending_chars"]):
            self.logger.warning(f"ç¼ºå°‘çµå°¾æ¨™é»ï¼š{content[-1]}")
            return False
            
        # æª¢æŸ¥ä¸å®Œæ•´å¥å­æ¨¡å¼
        text_for_pattern = content.rstrip("ï¼ã€‚ï¼Ÿï½!?~")
        for pattern in criteria["incomplete_patterns"]:
            if re.search(pattern, text_for_pattern):
                self.logger.warning(f"æª¢æ¸¬åˆ°ä¸å®Œæ•´å¥å­æ¨¡å¼ï¼š{pattern}")
                return False
                
        return True
        
    async def pre_generate_content(self, count: int = 3) -> List[str]:
        """é å…ˆç”Ÿæˆå¤šç¯‡å…§å®¹ï¼Œç”¨æ–¼å¿«å–
        
        Args:
            count: è¦ç”Ÿæˆçš„å…§å®¹æ•¸é‡
            
        Returns:
            List[str]: ç”Ÿæˆçš„å…§å®¹åˆ—è¡¨
        """
        contents = []
        tasks = []
        
        # å‰µå»ºå¤šå€‹å…§å®¹ç”Ÿæˆä»»å‹™
        for _ in range(count):
            tasks.append(self._generate_content())
            
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è™•ç†çµæœ
        for result in results:
            if isinstance(result, str) and len(result) > 20:
                contents.append(result)
                
        self.logger.info(f"é å…ˆç”Ÿæˆäº† {len(contents)}/{count} ç¯‡å…§å®¹")
        
        return contents
        
    async def get_content_stats(self) -> Dict[str, Any]:
        """ç²å–å…§å®¹ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        
        Returns:
            Dict[str, Any]: çµ±è¨ˆè³‡è¨Š
        """
        stats = {
            "cached_content_count": len(self.content_cache),
            "performance": self.performance_monitor.get_operation_stats("content_generation"),
            "api_stats": self.performance_monitor.api_stats.get("openai", {})
        }
        
        return stats

    def set_threads_handler(self, threads_handler):
        """è¨­ç½® Threads è™•ç†å™¨
        
        Args:
            threads_handler: Threads è™•ç†å™¨å¯¦ä¾‹
        """
        self.threads_handler = threads_handler
        self.logger.info("å·²è¨­ç½® Threads è™•ç†å™¨") 